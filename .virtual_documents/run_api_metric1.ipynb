from datetime import date
from IPython.display import Markdown, display

display(Markdown(f"""
# Run API

**Author:** Anthony Hauser<br>
**Affiliation:** Unisanté<br>
**Date:** {date.today()}<br>
**Project:** Omata

**Aim**: load images and run IA models through API to assess whether they show tobacco products

1) load libraries

The python script is partially based on : https://mljar.com/notebooks/openai-vision-local-image/?utm_source=chatgpt.com.

https://docs.together.ai/docs/inference-python
"""))


#load libraries and environment variables

#library
import os
import io
from dotenv import load_dotenv
from openai import OpenAI, AuthenticationError
import base64
import requests
import pandas as pd
import json
import re
from datetime import date

#set api key for open ai
#new_key=""
#os.system(f'setx OPENAI_API_KEY "{new_key}"')

#env variables
load_dotenv()
api_key=os.getenv("OPENAI_API_KEY") # get api key from environment
print(api_key)


# create OpenAI client
def create_client(api_key):
    try:
        client = OpenAI(api_key=api_key)
        client.models.list()#sanity check listing all availabel model
        return client
    except AuthenticationError:
        print("Incorrect API")
    return None
    
# Function to encode a single image
def encode_image(image_path):
    with open(image_path, "rb") as f:
        return base64.b64encode(f.read()).decode("utf-8")

#def resize_encode_image(image_path, resize=None):
    # Open image
#    img = Image.open(image_path)
    
    # Resize if requested
#    if resize is not None:
#        img.thumbnail((resize, resize))
        
    # Encode bytes to base64 string
 #   return base64.b64encode(img.tobytes()).decode("utf-8")

def resize_encode_image(image_path, resize=None):
    # Open image
    img = Image.open(image_path)
    
    # Resize if requested
    if resize is not None:
        img.thumbnail((resize, resize))
    
    # Save to bytes buffer in standard format (PNG)
    buffer = io.BytesIO()
    img.save(buffer, format="PNG")
    img_bytes = buffer.getvalue()
    
    # Encode to base64
    return base64.b64encode(img_bytes).decode("utf-8")



#load API 
client = create_client(api_key)
models = client.models.list()

# Print model IDs
#for model in models.data:
#    print(model.id)

model_name_list= ["gpt-4o-mini", "gpt-4o"]





#load and check dimension

from PIL import Image
from pathlib import Path
import pandas as pd

# Folder containing images
image_folder = Path(r"C:/TEMP/projects/omata/data/image_positive_controls/Images_test-20240424T090736Z-001/Images_test")

# Get all image paths
image_paths = list(image_folder.glob("*.jpg")) + \
              list(image_folder.glob("*.jpeg")) + \
              list(image_folder.glob("*.png"))
image_paths.sort()

# Extract file names, open images, and get sizes
file_names_pos1 = [p.name for p in image_paths]
image_sizes = [Image.open(p).size for p in image_paths]  # (width, height)

# Create a DataFrame
df_images = pd.DataFrame({
    "file_name": file_names_pos1,
    "width": [s[0] for s in image_sizes],
    "height": [s[1] for s in image_sizes]
})

# Display the DataFrame
print(df_images)


#convert to base64 and print

import matplotlib.pyplot as plt
import math

# Encode all images into a list
base64_images_pos1 = [resize_encode_image(path,resize=2000) for path in image_paths]#[encode_image(path) for path in image_paths]
num_images = len(base64_images_pos1)
print(f"Found {num_images} images.")

# Example: base64_images is your list of base64-encoded images
cols = 4  # adjust depending on number of images
rows = rows = math.ceil(num_images / cols)

plt.figure(figsize=(20, 4 * rows))
for idx, b64_img in enumerate(base64_images_pos1):
    # Decode base64 to image
    image_data = base64.b64decode(b64_img)
    image = Image.open(io.BytesIO(image_data))
    
    plt.subplot(rows, cols, idx + 1)
    plt.imshow(image)
    plt.axis('off')

plt.tight_layout()
plt.show()





#load and check dimension

# Folder containing images
image_folder = Path(r"C:/TEMP/projects/omata/data/image_negative_controls/instagram_batch1")

# Get all image paths
image_paths = list(image_folder.glob("*.jpg")) + \
              list(image_folder.glob("*.jpeg")) + \
              list(image_folder.glob("*.png"))
image_paths.sort()

# Extract file names, open images, and get sizes
file_names_neg1 = [p.name for p in image_paths]
image_sizes = [Image.open(p).size for p in image_paths]  # (width, height)

# Create a DataFrame
df_images = pd.DataFrame({
    "file_name": file_names_neg1,
    "width": [s[0] for s in image_sizes],
    "height": [s[1] for s in image_sizes]
})

# Display the DataFrame
print(df_images)


#load images
# Encode all images into a list
base64_images_neg1 = [resize_encode_image(path,resize=2000) for path in image_paths]
num_images = len(base64_images_neg1)
print(f"Found {num_images} images.")

# Example: base64_images is your list of base64-encoded images
cols = 4  # adjust depending on number of images
rows = rows = math.ceil(num_images / cols)

plt.figure(figsize=(20, 4 * rows))
for idx, b64_img in enumerate(base64_images_neg1):
    # Decode base64 to image
    image_data = base64.b64decode(b64_img)
    image = Image.open(io.BytesIO(image_data))
    
    plt.subplot(rows, cols, idx + 1)
    plt.imshow(image)
    plt.axis('off')

plt.tight_layout()
plt.show()





#load and check dimension

# Folder containing images
image_folder = Path(r"C:/TEMP/projects/omata/data/image_negative_controls/unsplash_batch1")

# Get all image paths
image_paths = list(image_folder.glob("*.jpg")) + \
              list(image_folder.glob("*.jpeg")) + \
              list(image_folder.glob("*.png"))
image_paths.sort()

# Extract file names, open images, and get sizes
file_names_neg2 = [p.name for p in image_paths]
image_sizes = [Image.open(p).size for p in image_paths]  # (width, height)

# Create a DataFrame
df_images = pd.DataFrame({
    "file_name": file_names_neg2,
    "width": [s[0] for s in image_sizes],
    "height": [s[1] for s in image_sizes]
})

# Display the DataFrame
print(df_images)



# Encode all images into a list
base64_images_neg2 = [resize_encode_image(path,resize=2000) for path in image_paths]
num_images = len(base64_images_neg2)
print(f"Found {num_images} images.")

# Example: base64_images is your list of base64-encoded images
cols = 4  # adjust depending on number of images
rows = math.ceil(num_images / cols)

plt.figure(figsize=(20, 4 * rows))
for idx, b64_img in enumerate(base64_images_neg2):
    # Decode base64 to image
    image_data = base64.b64decode(b64_img)
    image = Image.open(io.BytesIO(image_data))
    
    plt.subplot(rows, cols, idx + 1)
    plt.imshow(image)
    plt.axis('off')

plt.tight_layout()
plt.show()





#define function: image

import requests

def analyze_image(base64_image: str, model_name: str, instruction_text: str, api_key: str):
    """
    Send a base64-encoded image to the OpenAI API with a text instruction.

    Args:
        base64_image (str): Base64-encoded image.
        model_name (str): Model to use, e.g., 'gpt-4o'.
        instruction_text (str): Instruction/prompt for the model.
        api_key (str): OpenAI API key.

    Returns:
        str: Model's response.
    """
    # Prepare content
    content = [
        {"type": "text", "text": instruction_text},
        {"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{base64_image}"}}
    ]
    
    # Set headers
    headers = {
        "Content-Type": "application/json",
        "Authorization": f"Bearer {api_key}"
    }
    
    # Create payload
    payload = {
        "model": model_name,
        "messages": [{"role": "user", "content": content}],
        "max_tokens": 600
    }
    
    # Make API request
    response = requests.post("https://api.openai.com/v1/chat/completions", headers=headers, json=payload)
    response.raise_for_status()  # raise an error if request failed
    
    return response.json()["choices"][0]["message"]["content"]


#run function

#image
image_path = r"C:/TEMP/projects/omata/data/image_negative_controls/instagram_batch1/instagram_altoids1.png"
base64_image = encode_image(image_path)
#model
model_name = "gpt-4o"
#prompt
instruction_text = "Does this image display tobacco product? (Yes or No)"

result = analyze_image(base64_image, model_name, instruction_text, api_key)
print(result)





#define function: multiple images

def analyze_mult_images(base64_images: list, model_name: str, instruction_text: str, api_key: str):
    """
    Send a base64-encoded image to the OpenAI API with a text instruction.

    Args:
        base64_image (str): Base64-encoded image.
        model_name (str): Model to use, e.g., 'gpt-4o'.
        instruction_text (str): Instruction/prompt for the model.
        api_key (str): OpenAI API key.

    Returns:
        str: Model's response.
    """
    # Prepare content
    content = [
                {"type": "text", "text": instruction_text},
            ] + [
                {"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{b64}"}} 
                for b64 in base64_images
            ]
    
    # Set headers
    headers = {
        "Content-Type": "application/json",
        "Authorization": f"Bearer {api_key}"
    }
    
    # Create payload
    payload = {
        "model": model_name,
        "messages": [{"role": "user", "content": content}],
        "max_tokens": 600
    }
    
    # Make API request
    response = requests.post("https://api.openai.com/v1/chat/completions", headers=headers, json=payload)
    response.raise_for_status()  # raise an error if request failed
    
    return response.json()["choices"][0]["message"]["content"]


#run function

#image
base64_images_test = base64_images[:2] #already encoded
#model
model_name = "gpt-4o"
#prompt
instruction_text =  "Analyze these images. For each, answer: Yes or No if it shows a tobacco product."

result = analyze_mult_images(base64_images_test, model_name, instruction_text, api_key)
print(result)








#define functions
import math, random

#cost estimates
def estimate_openai_cost(usage: dict, model: str) -> dict:
    """
    Estimate the approximate cost of an OpenAI API call.

    Parameters:
        usage : dict
            The 'usage' field from the OpenAI API response.
        model : str
            The model used (e.g., "gpt-4", "gpt-4.1-mini", "gpt-3.5-turbo")

    Returns:
        dict with prompt_tokens, completion_tokens, total_tokens, estimated_cost_usd
    """
    # Token counts
    prompt_tokens = usage.get("prompt_tokens", 0)
    completion_tokens = usage.get("completion_tokens", 0)
    total_tokens = usage.get("total_tokens", 0)

    # Model rates per 1M tokens (USD)
    rates = { "gpt-4o": {"prompt": 2.50, "completion": 10.00},   #add cached input (but very small)       #https://platform.openai.com/docs/pricing
        "gpt-4o-mini": {"prompt": 0.15, "completion": 0.60}}

    # Use rates for the specified model, or default to 0
    model_rates = rates.get(model.lower(), {"prompt": 0, "completion": 0})

    # Compute cost
    
    input_cost = (prompt_tokens / 1_000_000) * model_rates["prompt"]
    output_cost = (completion_tokens / 1_000_000) * model_rates["completion"]
    total_cost = input_cost + output_cost
    return {
        "input_cost": input_cost,
        "output_cost": output_cost,
        "total_cost": total_cost
    }

#api gpt model
def analyze_mult_images_label(base64_images: list, img_names: list, model_name: str, instruction_text: str, api_key: str):
    # Build content with numbered images
    content = [{"type": "text", "text": instruction_text}]
    for img_name, b64 in zip(img_names, base64_images):
        content.append({"type": "text", "text": img_name})  # label
        content.append({"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{b64}"}})

    # Set headers
    headers = {
        "Content-Type": "application/json",
        "Authorization": f"Bearer {api_key}"
    }
    
    # Create payload
    payload = {
        "model": model_name,
        "messages": [
            {"role": "user", "content": content}
        ],
        "max_tokens": 600,
        "temperature": 0
    }
    
   # Extract response text
    response = requests.post("https://api.openai.com/v1/chat/completions", headers=headers, json=payload)
    response.raise_for_status()  # raise an error if request failed
    data = response.json()

    #extract usage
    usage = data.get("usage", {})
    usage_json = tokens_dict = {"prompt_tokens": usage.get("prompt_tokens"),
                                "completion_tokens": usage.get("completion_tokens"),
                                "total_tokens": usage.get("total_tokens")}
    #calculate price
    cost = estimate_openai_cost(usage, model_name)
    
    return {"response": data["choices"][0]["message"]["content"],
            "usage": usage_json,
            "cost": cost}

#run model ordering image randomly and by batches
def analyze_batch(base64_images: list, img_names: list, model_name: str, instruction_text: str, api_key: str, batch_size: int, max_retries=5):
    # Combine and shuffle together to preserve alignment
    combined = list(zip(base64_images, img_names))
    random.shuffle(combined)
    base64_images, img_names = zip(*combined)  # unzip back
    base64_images, img_names = list(base64_images), list(img_names)
    
    # Calculate number of batches
    n_batches = math.ceil(len(base64_images) / batch_size)
    print(f"Total batches: {n_batches}")
    
    
    batches = {}
    for i in range(n_batches):
        start = i * batch_size
        end = start + batch_size
        batch_names = img_names[start:end]
        batches[f"batch{i+1}"] = batch_names
    
    results = {}
    for batch_label, batch_names in batches.items():
        indices = [img_names.index(name) for name in batch_names]
        batch_images = [base64_images[i] for i in indices]

        # Retry loop
        for attempt in range(max_retries):
            try:
                result = analyze_mult_images_label(
                                                    batch_images,
                                                    batch_names,
                                                    model_name,
                                                    instruction_text,
                                                    api_key)
                break
            except requests.exceptions.HTTPError as e:
                if e.response.status_code == 429:
                    wait = (2 ** attempt) + random.random()
                    print(f"Rate limit hit. Waiting {wait:.1f}s before retry...")
                    time.sleep(wait)
                else:
                    raise
        else:
            #This else belongs to the "for attempt" loop — runs if never broken (i.e. all retries failed)
            raise Exception("Max retries exceeded for batch: " + batch_label)

        print("--")
        results[batch_label] = result  # return a list of
    
    return {"batches": batches,
            "results": results}

#to remove later
def analyze_batch_test(base64_images: list, img_names: list, model_name: str, instruction_text: str, api_key: str, batch_size: int):
    # Combine and shuffle together to preserve alignment
    combined = list(zip(base64_images, img_names))
    random.shuffle(combined)
    base64_images, img_names = zip(*combined)  # unzip back
    base64_images, img_names = list(base64_images), list(img_names)
    
    # Calculate number of batches
    n_batches = math.ceil(len(base64_images) / batch_size)
    print(f"Total batches: {n_batches}")
    
    batches = {}
    for i in range(n_batches):
        start = i * batch_size
        end = start + batch_size
        batch_names = img_names[start:end]
        batches[f"batch{i+1}"] = batch_names
    
    results = {}
    for batch_label, batch_names in batches.items():
        indices = [img_names.index(name) for name in batch_names]
        batch_images = [base64_images[i] for i in indices]
    
        print(batch_names)
    
        results[batch_label] = {"a"}  # return a list of
    
    return {"batches": batches,
            "results": results}
print("Functions loaded")


#function argument

#image
all_images = base64_images_neg1 + base64_images_neg2 + base64_images_pos1 #base64_images_neg2[:2] #[:28]
all_names = file_names_neg1 + file_names_neg2 + file_names_pos1 #file_names_neg2[:2]
outcomes = ["No"] * (len(file_names_neg1) + len(file_names_neg2)) + ["Yes"] * len(file_names_pos1)
print(img_names)
print("-")
print(outcomes)


print(len(all_images))
print(len(all_names))

#model
model_name = "gpt-4o-mini"

#prompt
instruction_text = """For each image below, respond in JSON format mapping each image name to an object with:
- "tobacco_product": "Yes" if the image shows or suggests any tobacco-related product, activity, or advertisement, even if the product itself is not directly visible (e.g., a person smoking, cigarette smoke, a tobacco brand logo or a slogan related to a tobacco product). Otherwise, "No".
- "type": If "tobacco_product" is "Yes", indicate the specific type or context related to tobacco use (e.g., "cigarettes", "person smoking", "cigarette smoke", "cigarette advertising", "cigarette packs", "loose tobacco pouch", "cigar", "vape", "e-cigarette", "hookah", "snus", "chewing tobacco", "rolling tobacco", "tobacco brand logo", "tobacco slogan", etc.). If "tobacco_product" is "No", put "NA".
- "main_elements": List the main visible elements in the image (e.g., "person", "table", "car", "beach").

Example output:
{
  "image1_instagram.jpg": {"tobacco_product": "Yes", "type": "person smoking, cigarette smoke", "main_elements": "chair, table, 2 people"},
  "james_blabla.jpg": {"tobacco_product": "No", "type": "NA", "main_elements": "candle, steam, chocolate"}
}
"""



#test function for a subset

base64_images = all_images[:2]
img_names = all_names[:2]

result = analyze_mult_images_label(base64_images, img_names, model_name, instruction_text, api_key)
print(result)


#test function by batches
rundate = date.today().strftime("%Y%m%d")#used to assign name of results

n_split = 5
i_split = 5
base64_images = all_images[(i_split-1)::n_split] #[:3]
img_names = all_names[(i_split-1)::n_split] #[:3]
print(img_names)

#plot one image to check
pos=0
print(img_names[pos])
image_data = base64.b64decode(base64_images[pos])
image = Image.open(io.BytesIO(image_data))
plt.imshow(image)

print(img_names)
print(len(img_names))

# Parameters
batch_size = 1

#run model
results = analyze_batch(base64_images, img_names, model_name, instruction_text, api_key, batch_size)
batches = results["batches"] #batch img_names
results = results["results"] #results about classification, usage and cost

print(results["batch1"]["response"])


print(len(base64_images))
print(len(img_names))
print(img_names)
print(results["batch20"]["response"])





#function to extract results

#batch-level results: usage and costs
def extract_batch_level(results, batches):
    #batches
    img_names_allbatches = [img for imgs in batches.values() for img in imgs]
    batch_names = list(batches.keys())
    batches_df = pd.DataFrame({
        'batch_name':batch_names,
        'img_names': ['; '.join(imgs) for imgs in batches.values()]
    })
    print(img_names_allbatches)
    print(len(img_names_allbatches))
    
    
    #Usage and cost
    #extract usage for each batch
    usage = [batch_data["usage"] for batch_data in results.values()]
    #assign name to each batch
    usage = dict(zip(batch_names, usage))
    #convert to df using name of each element in the index column
    usage_df = pd.DataFrame.from_dict(usage, orient='index').reset_index()
    #rename index column into batch_name
    usage_df = usage_df.rename(columns={'index': 'batch_name'})
    
    #Cost
    #extract usage for each batch
    cost = [batch_data["cost"] for batch_data in results.values()]
    #assign name to each batch
    cost = dict(zip(batch_names, cost))
    #convert to df using name of each element in the index column
    cost_df = pd.DataFrame.from_dict(cost, orient='index').reset_index()
    #rename index column into batch_name
    cost_df = cost_df.rename(columns={'index': 'batch_name'})
    
    #Combine two df
    usage_cost_df = pd.merge(usage_df, cost_df, on='batch_name')
    
    #add sum
    total_usage_cost_df = pd.DataFrame([usage_cost_df.select_dtypes(include='number').sum()])
    total_usage_cost_df['batch_name'] = 'total_batch'
    usage_cost_df = pd.concat([usage_cost_df, total_usage_cost_df], ignore_index=True)

    return {"img_names_allbatches": img_names_allbatches,
            "batches_df": batches_df,
            "usage_cost_df": usage_cost_df}

#Extract response and convert to dict
def extract_response(results, img_names_allbatches):
    #extract response (this gives a list of text elements
    responses = [batch_data["response"] for batch_data in results.values()]
    #remove "json" or "```" at the beginning of each text element
    cleaned_responses = [re.sub(r"```json|```", "", r).strip() for r in responses]
    #convert each text elements into a dict object (of length batch_size)
    parsed_dicts = [json.loads(r) for r in cleaned_responses]
    #merge all dict element into a single dict
    merged_responses = {}
    for d in parsed_dicts:
        merged_responses.update(d)
    #print(json.dumps(merged_results, indent=2))
    
    #Convert to dataframe
    #convert to a list of rows
    rows = []
    for label, info in merged_responses.items():
        # info is a dict like {"tobacco_product": "Yes", "type": "box of cigarettes"}
        row = {"img_names": label}  # first column = image label
        row.update(info)           # add all inner dict items as separate columns
        rows.append(row)
    # Convert to DataFrame
    responses_df = pd.DataFrame(rows)
    #print(responses_df)
    
    #Add true outcome
    true_responses_df = pd.DataFrame({
        'img_names': all_names,
        'tobacco_product_true': outcomes
    })
    
    #check
    a = responses_df.img_names
    b = img_names
    print( list(set(a) - set(b))) #made up names by the model
    print( list(set(b) - set(a))) #true names that were replaced by made up ones
    
    #replace img_names column by correct names as the model may have created wrong ones
    responses_df['img_names'] = img_names_allbatches
    
    #print(true_responses_df)
    responses_df = pd.merge(responses_df, true_df, on='img_names')

    return(responses_df)
print("Functions loaded")


#usage and cost
return_list = extract_batch_level(results, batches)
usage_cost_df = return_list["usage_cost_df"]
img_names_allbatches = return_list["img_names_allbatches"]
display(usage_cost_df)

#save batches_df and usage_cost_df
usage_cost_df.to_csv(f"results/classification/infobatch_batchsize{batch_size}_{rundate}_{model_name}_test_{i_split}.csv", index=False)


#response
responses_df = extract_response(results, img_names_allbatches)
display(responses_df)
#save
responses_df.to_csv(f"results/classification/classification_batchsize{batch_size}_{rundate}_{model_name}_test_{i_split}.csv", index=False)





#load and combine responses
batchsize=1
rundate="20251111"
model_name = "gpt-4o-mini"

responses_dfs = []

for i_split in range(1, 6):
    file_path = f"results/classification/classification_batchsize{batch_size}_{rundate}_{model_name}_test_{i_split}.csv"
    df = pd.read_csv(file_path)
    responses_dfs.append(df)

all_responses_df = pd.concat(responses_dfs, ignore_index=True)





contingency_table = pd.crosstab(all_responses_df['true_outcomes'], all_responses_df['tobacco_product'], margins=True)
contingency_table.index = ['Actual_No', 'Actual_Yes', 'Total']
contingency_table.columns = ['Predicted_No', 'Predicted_Yes', 'Total']
display(contingency_table)


TP = contingency_table.loc['Actual_Yes', 'Predicted_Yes']
FN = contingency_table.loc['Actual_Yes', 'Predicted_No']
TN = contingency_table.loc['Actual_No', 'Predicted_No']
FP = contingency_table.loc['Actual_No', 'Predicted_Yes']

sensitivity = TP / (TP + FN)
specificity = TN / (TN + FP)
accuracy = (TP + TN) / (TP + TN + FP + FN)

print(f"Sensitivity (True Positive Rate): {sensitivity:.2f}")
print(f"Specificity (True Negative Rate): {specificity:.2f}")
print(f"Accuracy: {accuracy:.2f}")





#check wrong classification
#wrong classification
filtered_df = all_responses_df[(all_responses_df['tobacco_product']=="No") & (all_responses_df['true_outcomes']=="Yes")]

display(filtered_df)

#plot
img_names_fn = filtered_df['img_names'].tolist()
print(img_names_fn)
which_pos = [all_names.index(x) for x in img_names_fn]
num_images = len(which_pos)
print(num_images)
images_fn = [all_images[i] for i in which_pos]
print([all_names[i] for i in which_pos]) #check that it corresponds to img_names_sel

cols = 2  # adjust depending on number of images
rows = math.ceil(num_images / cols)

plt.figure(figsize=(20, 4 * rows))
for idx, b64_img in enumerate(images_fn):
    # Decode base64 to image
    image_data = base64.b64decode(b64_img)
    image = Image.open(io.BytesIO(image_data))
    
    plt.subplot(rows, cols, idx + 1)
    plt.imshow(image)
    plt.axis('off')
    plt.title(img_names_fn[idx], fontsize=10)

plt.tight_layout()
plt.show()





#filter false positive
filtered_df = all_responses_df[(all_responses_df['tobacco_product']=="Yes") & (all_responses_df['true_outcomes']=="No")]

display(filtered_df)

#plot
img_names_fp = filtered_df['img_names'].tolist()
print(img_names_fp)
which_pos = [all_names.index(x) for x in img_names_fp]
num_images = len(which_pos)
print(num_images)
images_fp = [all_images[i] for i in which_pos]
print([all_names[i] for i in which_pos]) #check that it corresponds to img_names_sel

cols = 2  # adjust depending on number of images
rows = math.ceil(num_images / cols)

plt.figure(figsize=(20, 4 * rows))
for idx, b64_img in enumerate(images_fp):
    # Decode base64 to image
    image_data = base64.b64decode(b64_img)
    image = Image.open(io.BytesIO(image_data))
    
    plt.subplot(rows, cols, idx + 1)
    plt.imshow(image)
    plt.axis('off')
    plt.title(img_names_fp[idx], fontsize=10)

plt.tight_layout()
plt.show()





#run function for misclassified images
model_name="gpt-4o" # #model_name="gpt-4o-mini"
# Parameters
batch_size = 1 #len(img_names_sel)

instruction_text1 = """For each image below, respond in JSON format mapping each image name to an object with:
- "tobacco_product": "Yes" if a tobacco product is detected, "No" otherwise
- "type": If "tobacco_product" is "Yes", indicate the specific type (e.g., "cigarettes", "box of cigarettes", "cigar", "puff", "vape", "snus", "chewing tobacco", "hookah", "rolling tobacco", "e-cigarette", etc.). If "tobacco_product" is "No", put "NA"
- "main_elements": List the main elements displayed in the image.

Example output:
{
  "image1_instagram.jpg": {"tobacco_product": "Yes", "type": "cigarettes","main_elements":"chair, table, 2 people"},
  "james_blabla.jpg": {"tobacco_product": "No", "type": "NA","main_elements":"candle, steam, chocolate"}
}"""

instruction_text2 = """For each image below, respond in JSON format mapping each image name to an object with:
- "tobacco_product": "Yes" if there is any object that is related to tobacco product, "No" otherwise
- "type": If "tobacco_product" is "Yes", indicate the specific type regarding the activity and/or object (e.g., "cigarettes","cigarette smoke", "cigarette advertising", "box of cigarettes", "cigar", "puff", "vape", "snus", "chewing tobacco", "hookah", "rolling tobacco", "e-cigarette", etc.). If "tobacco_product" is "No", put "NA"
- "main_elements": List the main elements displayed in the image.

Example output:
{
    "image1_instagram.jpg": {"tobacco_product": "Yes", "type": "cigarettes, smoke","main_elements":"chair, table, 2 people"},
    "james_blabla.jpg": {"tobacco_product": "No", "type": "NA","main_elements":"candle, steam, chocolate"}
}
"""

instruction_text3 = """For each image below, respond in JSON format mapping each image name to an object with:
- "tobacco_product": "Yes" if the image shows or suggests any tobacco-related product, activity, or advertisement, even if the product itself is not directly visible (e.g., a person smoking, cigarette smoke, a tobacco brand logo or a slogan related to a tobacco product). Otherwise, "No".
- "type": If "tobacco_product" is "Yes", indicate the specific type or context related to tobacco use (e.g., "cigarettes", "person smoking", "cigarette smoke", "cigarette advertising", "cigarette packs", "loose tobacco pouch", "cigar", "vape", "e-cigarette", "hookah", "snus", "chewing tobacco", "rolling tobacco", "tobacco brand logo", "tobacco slogan", etc.). If "tobacco_product" is "No", put "NA".
- "main_elements": List the main visible elements in the image (e.g., "person", "table", "car", "beach").

Example output:
{
  "image1_instagram.jpg": {"tobacco_product": "Yes", "type": "person smoking, cigarette smoke", "main_elements": "chair, table, 2 people"},
  "james_blabla.jpg": {"tobacco_product": "No", "type": "NA", "main_elements": "candle, steam, chocolate"}
}
"""

#run model
results_fp = analyze_batch(images_fp, img_names_fp, model_name, instruction_text, api_key, batch_size) #base64_images_sel[4:5]
batches_fp = results_fp["batches"] #batch img_names
results_fp = results_fp["results"] #results about classification, usage and cost

print(results_fp["batch1"]["response"])


#usage and cost
return_list = extract_batch_level(results_fp, batches_fp)
usage_cost_df_fp = return_list["usage_cost_df"]
img_names_allbatches_fp = return_list["img_names_allbatches"]
display(usage_cost_df_fp)

#save batches_df and usage_cost_df
usage_cost_df_fp.to_csv(f"results/classification/infobatch_batchsize{batch_size}_{rundate}_{model_name}_test_fp.csv", index=False)


#response
responses_df_fp = extract_response(results_fp, img_names_allbatches_fp)
display(responses_df_fp)
#save
responses_df_fp.to_csv(f"results/classification/classification_batchsize{batch_size}_{rundate}_{model_name}_test_fp.csv", index=False)





#run function for misclassified images
model_name="gpt-4o" # #model_name="gpt-4o-mini"
# Parameters
batch_size = 1 #len(img_names_sel)

#run model
results_fn = analyze_batch(images_fn, img_names_fn, model_name, instruction_text, api_key, batch_size) #base64_images_sel[4:5]
batches_fn = results_fn["batches"] #batch img_names
results_fn = results_fn["results"] #results about classification, usage and cost

print(results_fn["batch1"]["response"])


#usage and cost
return_list = extract_batch_level(results_fn, batches_fn)
usage_cost_df_fn = return_list["usage_cost_df"]
img_names_allbatches_fn = return_list["img_names_allbatches"]
display(usage_cost_df_fn)

#save batches_df and usage_cost_df
usage_cost_df_fn.to_csv(f"results/classification/infobatch_batchsize{batch_size}_{rundate}_{model_name}_test_fn.csv", index=False)


#response
responses_df_fn = extract_response(results_fn, img_names_allbatches_fn)
display(responses_df_fn)
#save
responses_df_fn.to_csv(f"results/classification/classification_batchsize{batch_size}_{rundate}_{model_name}_test_fp.csv", index=False)
